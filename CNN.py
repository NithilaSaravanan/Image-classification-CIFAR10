# -*- coding: utf-8 -*-
"""MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KiuWUc1SYL3BjSQt_gwtxe9A_6W9tXQe
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Apr 10 01:51:15 2020

@author: nithila
"""
import torch
import torchvision
import torchvision.transforms as transforms

import matplotlib.pyplot as plt
import numpy as np

import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data.sampler import SubsetRandomSampler

import torch.optim as optim
import seaborn as sns

#To check if GPU is active (Running on colab)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

transform_trn = transforms.Compose(
   [
    transforms.RandomCrop(32, padding=4),#Crops and pads the image
    transforms.RandomHorizontalFlip(), #Flips the image with a 0.5 probability
    transforms.ToTensor(),#Converts the input to a tensor
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])#Normalizes the data based on the 3-channel mean and std dev values
    

transform_test = transforms.Compose(
    [
     transforms.ToTensor(),
     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
     ])
    

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform_trn)

batch_size = 4 
validation_split = .2
shuffle_dataset = True
random_seed= 42

# Creating data indices for training and validation splits:
dataset_size = len(trainset)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))
if shuffle_dataset :
    np.random.seed(random_seed)
    np.random.shuffle(indices)
train_indices, val_indices = indices[split:], indices[:split]

train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, 
                                           sampler=train_sampler)
validationloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                                sampler=valid_sampler)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(trainloader)
images, labels = dataiter.next()

# ConvNet class definition
# Taking 3 channel data and creating 3 blocks of Convolution layers (with ReLu activation functions), intertwined with regularization  
# techniques like dropout and batchnorm, which are then all connected using a fully connected layer
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()

        self.convol_layer = nn.Sequential( 
            
               # Convolution Block 1
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            # Convolution Block 2
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout2d(p=0.05),

            # Convolution Block 3
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )

# Fully Connected layer
        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),
            nn.Linear(4096, 1024),
            nn.ReLU(inplace=True),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
            nn.Linear(512, 10)
        )


    def forward(self, x):
        """Perform forward."""
        
        # conv layers
        x = self.convol_layer(x)
        
        # flatten
        x = x.view(x.size(0), -1) # flatten it to a vector to feed it to the fully connected network
        
        # fc layer
        x = self.fc_layer(x)

        return x

net = Net().to(device)
criterion = nn.CrossEntropyLoss()
#optimizer = optim.Adam(net.parameters(), lr=0.0005)
#optimizer = optim.Adagrad(net.parameters()) 
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)   
#optimizer = optim.SGD(net.parameters(), lr=0.001)
    
'''

# check if CUDA is available
trn_gpu = tor.cuda.is_available()

if not trn_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')
    
'''






'''
# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
'''





for epoch in range(15):  # loop over the dataset multiple times

    running_loss = 0.0
    correct=0
    total=0
    
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        
        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print("[%d, %5d] loss : %.3f , Training Accuracy : %.3f " %
                  (epoch + 1, i + 1, running_loss / 2000, 100 * correct / total))
            running_loss = 0.0

print('Finished Training')

PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)

dataiter = iter(testloader)
images, labels = dataiter.next()

'''
# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
'''

net = Net()
net.load_state_dict(torch.load(PATH))

correct2 = 0
total2 = 0

with torch.no_grad():

  for data2 in validationloader:
      images2, labels2 = data2
      outputs2 = net(images2)
      _, predicted2 = torch.max(outputs2.data, 1)
      total2 += labels2.size(0)
      correct2 += (predicted2 == labels2).sum().item()

print('Validation Accuracy : %.3f %%' % (
    100 * correct2 / total2))

#net = Net()
#outputs = net(images)
#_, predicted = torch.max(outputs, 1)

#print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
                              #for j in range(4)))

correct1 = 0
total1 = 0
with torch.no_grad():
    for data in testloader:
        images1, labels1 = data
        outputs1 = net(images1)
        _, predicted1 = torch.max(outputs1.data, 1)
        total1 += labels1.size(0)
        correct1 += (predicted1 == labels1).sum().item()

print('Accuracy of the network on the 10000 test images: %.3f %%' % (
    100 * correct1 / total1))

# Confusion matrix of all classes
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
confusion_matrix = np.zeros([10,10], int)
with torch.no_grad():
    for data3 in testloader:
        images3, labels3 = data3
        outputs3 = net(images3)
        _, predicted3 = torch.max(outputs3, 1)
        c = (predicted3 == labels3).squeeze()
        for i in range(4):
            label3 = labels3[i]
            class_correct[label3] += c[i].item()
            class_total[label3] += 1
        for i, l in enumerate(labels3):
            confusion_matrix[l.item(), predicted3[i].item()] += 1


for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
    
fig, ax = plt.subplots(1,1,figsize=(8,6))
ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Purples'))
plt.ylabel('Actual Classes')
plt.yticks(range(10), classes)
plt.xlabel('Predicted Classes')
plt.xticks(range(10), classes)
plt.show()

# Analysis to compare Cross-entropy loss of MLP and CNN
# Analysis to compare training, validation and testing performance

cnn_ce_loss = [1.237, 0.947, 0.802, 0.7, 0.624, 0.597, 0.522, 0.506, 0.462, 0.443, 0.416, 0.372, 0.367, 0.346, 0.333]
mlp_ce_loss = [1.6151, 1.4794, 1.404, 1.3509, 1.2830, 1.24326, 1.1856, 1.15501, 1.1272, 1.08375, 1.0224, 0.9963, 0.9568, 0.92, 0.8803]
train_accuracy = [0.63282, 0.77468, 0.84847, 0.86225, 0.88782]
val_accuracy = [0.678, 0.78390, 0.82470, 0.835, 0.84940]
test_accuracy = [0.67980, 0.781, 0.82860, 0.82960, 0.84670]
x_accuracy = [2,5,10,12,15]

f, axe = plt.subplots(1, 2, figsize=(10,4))
x = np.arange(1,16)

a = axe[0]
a.set_ylabel('Cross-Entropy Loss')
a.set_xlabel('No of Epochs')
a.set_ylim(0.2, 1.8)
a.plot(x, cnn_ce_loss, 'b-', label = 'CNN Cross Entropy loss')
a.plot(x, mlp_ce_loss, 'b--', label = 'MLP Cross Entropy Loss')
a.legend()

b = axe[1]
b.set_ylabel('Accuracy')
b.set_xlabel('No of Epochs')
b.plot(x_accuracy, train_accuracy, 'b-', label = 'training accuracy')
b.plot(x_accuracy, val_accuracy, 'y--', label = 'val accuracy')
b.plot(x_accuracy, test_accuracy, 'r-', label = 'test accuracy')
b.legend()

# Analysis to compare different optimizers training and validation accuracy
x1 = [2,5,10,12,15]
train_sgd_momentum = [0.6382, 0.77468, 0.84847, 0.86225, 0.88782]
val_sgd_momentum = [0.678, 0.7830, 0.82470, 0.835, 0.84940]
train_sgd = [0.4678, 0.68483, 0.74875, 0.80830, 0.83183]
val_sgd = [0.53390, 0.68820, 0.77370, 0.79550, 0.80930]
train_adam = [0.33708, 0.661, 0.71783, 0.78080, 0.80093]
val_adam = [0.33790, 0.66960, 0.70660, 0.765, 0.79180]
train_adagrad = [0.45205, 0.62380, 0.74802, 0.73718, 0.69812]
val_adagrad = [0.49630, 0.62810, 0.72730, 0.72940, 0.68670]

f1, axe1 = plt.subplots(1, 2, figsize=(10,4), sharex=True)

c = axe1[0]
c.set_ylabel('Training Accuracy')
c.set_xlabel('No of epochs')
c.plot(x1, train_sgd_momentum, 'b-', label = 'SGD with momentum')
c.plot(x1, train_sgd, 'y-', label = 'SGD')
c.plot(x1, train_adam, 'g-', label = 'ADAM')
c.plot(x1, train_adagrad, 'r-', label = 'AdaGrad')
c.legend()

d = axe1[1]
d.set_ylabel('Validation Accuracy')
d.set_xlabel('No of epochs')
d.plot(x1, val_sgd_momentum, 'b-', label = 'SGD with momentum')
d.plot(x1, val_sgd, 'y-', label = 'SGD')
d.plot(x1, val_adam, 'g-', label = 'ADAM')
d.plot(x1, val_adagrad, 'r-', label = 'AdaGrad')
d.legend()